{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****v3****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 209\u001b[0m\n\u001b[0;32m    206\u001b[0m num_rows_to_scrape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Change this to the desired number of rows, or set it to None\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Call the function with the airport_list and the specified number of rows\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m \u001b[43mscrape_departures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mairport_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows_to_scrape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 163\u001b[0m, in \u001b[0;36mscrape_departures\u001b[1;34m(airport_list, num_rows)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Local_elements:\n\u001b[0;32m    161\u001b[0m         Local \u001b[38;5;241m=\u001b[39m Local_elements\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m local_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(Local,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Parse UTC time string into datetime object with a dummy date\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver import Edge\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Define the function to click the \"Load earlier flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_earlier_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load earlier flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "# Define the function to click the \"Load later flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_later_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load later flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "def save_data_to_csv(data, airport_name, current_date):\n",
    "    # Remove invalid characters from the airport name\n",
    "    airport_name = re.sub(r'[\\\\/:\"*?<>|]+', '', airport_name)\n",
    "    \n",
    "    # Create folder path with date attached\n",
    "    folder_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}'  # Change this to the desired folder path\n",
    "    os.makedirs(folder_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    \n",
    "    # Create file path with airport name and date attached\n",
    "    file_path = os.path.join(folder_path, f\"Arrivals_{airport_name}_{current_date}.csv\")  # Add .csv extension\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def get_data_with_date(data,time_difference):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Initialize variables to store the last encountered date\n",
    "    last_date = ''\n",
    "    last_date_with_year = ''\n",
    "    \n",
    "    # Iterate through the data to append date with year as needed\n",
    "    for row in data:\n",
    "        if row[0].startswith(('Monday,', 'Tuesday,', 'Wednesday,', 'Thursday,', 'Friday,', 'Saturday,', 'Sunday,')):\n",
    "            last_date = row[0]\n",
    "            last_date_with_year = last_date + \" \" + str(current_year)\n",
    "        elif last_date_with_year:  # Append date with year if it exists\n",
    "            row.append(last_date_with_year)\n",
    "            row.append(time_difference)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def scrape_departures(airport_list, num_rows=None):\n",
    "    # Determine the number of rows to iterate based on the provided parameter\n",
    "    if num_rows is not None:\n",
    "        airport_list = airport_list.head(num_rows)\n",
    "    \n",
    "    # Get current date\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Checkpoint file path\n",
    "    checkpoint_file_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}/ARRcheckpoint.csv'\n",
    "    \n",
    "    # Check if checkpoint file exists\n",
    "    if os.path.isfile(checkpoint_file_path):\n",
    "        checkpoint_df = pd.read_csv(checkpoint_file_path)\n",
    "        processed_airports = set(checkpoint_df['Name'])\n",
    "    else:\n",
    "        processed_airports = set()\n",
    "    \n",
    "    \n",
    "    is_logged_in = False\n",
    "    # Initialize the Edge driver with the specified options\n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    \n",
    "    # Loop through the specified number of rows in the airport list\n",
    "    for _, airport in airport_list.iterrows():\n",
    "        if airport['Name'] in processed_airports:\n",
    "            continue\n",
    "        \n",
    "        data = []\n",
    "        driver = webdriver.Edge(options=options)\n",
    "        # Append '/departures' to the link\n",
    "        departure_link = airport['Link'] + '/arrivals'\n",
    "        \n",
    "        # Open the departure link in browser\n",
    "        \n",
    "        driver.get(departure_link)\n",
    "        \n",
    "        time.sleep(4)\n",
    "\n",
    "        # Wait for the button to appear\n",
    "        try:\n",
    "            button = driver.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "        if not is_logged_in:\n",
    "            time.sleep(9)  # Sleep for 5 seconds before login\n",
    "            button = driver.find_element(By.ID, \"auth-button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            email = \"iheb.benjeddi9573@gmail.com\"\n",
    "            password = \"IHEBjihedAziz2024!!?\"\n",
    "            EmailField = driver.find_element(By.XPATH, \"/html/body/div[10]/div/div/div/form/div[1]/div/input\")\n",
    "            passwordField = driver.find_element(By.XPATH, \"/html/body/div[10]/div/div/div/form/div[2]/div/input\")\n",
    "            EmailField.send_keys(email)\n",
    "            passwordField.send_keys(password)\n",
    "            login = driver.find_element(By.XPATH, \"/html/body/div[10]/div/div/div/form/button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", login)\n",
    "            time.sleep(2)\n",
    "            # Set flag to True after logging in once\n",
    "            is_logged_in = True\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading earlier flights\n",
    "        click_load_earlier_until_disappear(driver)\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading later flights\n",
    "        click_load_later_until_disappear(driver)\n",
    "\n",
    "        # Get the HTML content of the page after loading all flights\n",
    "        html = driver.page_source\n",
    "        time.sleep(5)\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Initialize UTC and Local time strings\n",
    "        UTC = ''\n",
    "        Local = ''\n",
    "\n",
    "        # Regular expression pattern to match the time format HH:MM\n",
    "        time_pattern = re.compile(r'\\d{2}:\\d{2}')\n",
    "\n",
    "        # Loop until the Local time matches the time format\n",
    "        while not time_pattern.match(Local):\n",
    "            # Fetch UTC and Local time elements here\n",
    "            UTC_elements = soup.find('span', class_='text-base')\n",
    "            if UTC_elements:\n",
    "                UTC = UTC_elements.text.strip()\n",
    "\n",
    "            Local_elements = soup.find('span', class_='clock-time ng-binding')\n",
    "            if Local_elements:\n",
    "                Local = Local_elements.text.strip()\n",
    "            \n",
    "            time.sleep(2)\n",
    "\n",
    "        local_time = datetime.strptime(Local,\"%H:%M\")\n",
    "        # Parse UTC time string into datetime object with a dummy date\n",
    "        utc_time = datetime.strptime(UTC,\"%H:%M\")\n",
    "        time_difference = utc_time - local_time\n",
    "\n",
    "        table = soup.find('table', class_='table table-condensed table-hover data-table m-n-t-15')\n",
    "       \n",
    "        # Extract data from the table\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    # Ensure consistent structure of each row\n",
    "                    row_data = [cell.text.strip() for cell in cells]\n",
    "                    # If row has fewer fields, add empty strings to match the expected number of fields\n",
    "                    if len(row_data) < 7:\n",
    "                        row_data.extend([''] * (7 - len(row_data)))\n",
    "                    row_data.append(airport['Name'])  # Append airport name to each row\n",
    "                    data.append(row_data)\n",
    "\n",
    "        driver.quit()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Process data to add date with date\n",
    "        data = get_data_with_date(data,time_difference)\n",
    "        # Save data to CSV file for the current airport\n",
    "        save_data_to_csv(data, airport['Name'], current_date)\n",
    "        \n",
    "        # Update processed airports set\n",
    "        processed_airports.add(airport['Name'])\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_df = pd.DataFrame({'Name': list(processed_airports)})\n",
    "        checkpoint_df.to_csv(checkpoint_file_path, index=False)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "airport_list = pd.read_csv(\"airport_list.csv\", header=None, names=[\"Name\", \"Link\"])\n",
    "\n",
    "# Specify the number of rows to scrape (if desired), or leave it as None to scrape all rows\n",
    "num_rows_to_scrape = None # Change this to the desired number of rows, or set it to None\n",
    "\n",
    "# Call the function with the airport_list and the specified number of rows\n",
    "scrape_departures(airport_list, num_rows_to_scrape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'airport_data_with_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     p\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# After getting airport_data_with_date from scraping\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m produce_to_kafka(\u001b[43mairport_data_with_date\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'airport_data_with_date' is not defined"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "\n",
    "# Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "\n",
    "def produce_to_kafka(data_df):\n",
    "    p = Producer(producer_config)\n",
    "\n",
    "    def delivery_report(err, msg):\n",
    "        \"\"\" Called once for each message produced to indicate delivery result.\n",
    "            Triggered by poll() or flush(). \"\"\"\n",
    "        if err is not None:\n",
    "            print('Message delivery failed: {}'.format(err))\n",
    "        else:\n",
    "            print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        # Convert row to JSON\n",
    "        json_data = row.to_json()\n",
    "\n",
    "        # Trigger any available delivery report callbacks from previous produce() calls\n",
    "        p.poll(0)\n",
    "\n",
    "        # Asynchronously produce a message.\n",
    "        p.produce('Arrivals', json_data.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "    # Wait for any outstanding messages to be delivered and delivery report callbacks to be triggered.\n",
    "    p.flush()\n",
    "\n",
    "# After getting airport_data_with_date from scraping\n",
    "produce_to_kafka(airport_data_with_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**full code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver import Edge\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "\n",
    "# Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "\n",
    "def produce_to_kafka(data_list):\n",
    "    p = Producer(producer_config)\n",
    "\n",
    "    def delivery_report(err, msg):\n",
    "        \"\"\" Called once for each message produced to indicate delivery result.\n",
    "            Triggered by poll() or flush(). \"\"\"\n",
    "        if err is not None:\n",
    "            print('Message delivery failed: {}'.format(err))\n",
    "        else:\n",
    "            print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "    for data in data_list:\n",
    "        # Convert data to JSON\n",
    "        json_data = json.dumps(data)\n",
    "\n",
    "        # Trigger any available delivery report callbacks from previous produce() calls\n",
    "        p.poll(0)\n",
    "\n",
    "        # Asynchronously produce a message.\n",
    "        p.produce('Arrivals', json_data.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "    # Wait for any outstanding messages to be delivered and delivery report callbacks to be triggered.\n",
    "    p.flush()\n",
    "\n",
    "def get_date_with_year(data):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    numeros_lignes = []\n",
    "    days = []\n",
    "    \n",
    "    # Convert data list to DataFrame\n",
    "    data_df = pd.DataFrame(data)\n",
    "    \n",
    "    for index, row in data_df.iterrows():\n",
    "        if row[0].split()[0] in [\"Monday,\", \"Tuesday,\", \"Wednesday,\", \"Thursday,\", \"Friday,\", \"Saturday,\", \"Sunday,\"]:\n",
    "            numeros_lignes.append(index)\n",
    "            days.append(row[0] + \" \" + str(current_year))  # Append current year\n",
    "    \n",
    "    # Add 'date' column to the DataFrame\n",
    "    data_df['date'] = ''\n",
    "    \n",
    "    for i in range(len(numeros_lignes) - 1):\n",
    "        data_df.iloc[numeros_lignes[i] + 1:numeros_lignes[i + 1] + 1, -1] = days[i]\n",
    "    \n",
    "    data_df.iloc[numeros_lignes[-1] + 1:-1, -1] = days[-1]\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "# Define the function to click the \"Load earlier flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_earlier_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load earlier flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except ElementNotInteractableException:\n",
    "            break\n",
    "\n",
    "# Define the function to click the \"Load later flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_later_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load later flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except ElementNotInteractableException:\n",
    "            break\n",
    "\n",
    "def scrape_departures(airport_list, num_rows=None):\n",
    "    data = []\n",
    "    \n",
    "    # Determine the number of rows to iterate based on the provided parameter\n",
    "    if num_rows is not None:\n",
    "        airport_list = airport_list.head(num_rows)\n",
    "    \n",
    "    # Loop through the specified number of rows in the airport list\n",
    "    for _, airport in airport_list.iterrows():\n",
    "        # Append '/departures' to the link\n",
    "        departure_link = airport['Link'] + '/arrivals'\n",
    "        \n",
    "        # Open the departure link in browser\n",
    "        driver = Edge()\n",
    "        driver.get(departure_link)\n",
    "        \n",
    "        time.sleep(4)\n",
    "\n",
    "        # Wait for the button to appear\n",
    "        button = driver.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "\n",
    "        # Click on the button\n",
    "        driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading earlier flights\n",
    "        click_load_earlier_until_disappear(driver)\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading later flights\n",
    "        click_load_later_until_disappear(driver)\n",
    "\n",
    "        # Get the HTML content of the page after loading all flights\n",
    "        html = driver.page_source\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Find the table element\n",
    "        table = soup.find('table', class_='table table-condensed table-hover data-table m-n-t-15')\n",
    "        \n",
    "        # Extract data from the table\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    # Ensure consistent structure of each row\n",
    "                    row_data = [cell.text.strip() for cell in cells]\n",
    "                    # If row has fewer fields, add empty strings to match the expected number of fields\n",
    "                    if len(row_data) < 7:\n",
    "                        row_data.extend([''] * (7 - len(row_data)))\n",
    "                    row_data.append(airport['Name'])  # Append airport name to each row\n",
    "                    data.append(row_data)\n",
    "        \n",
    "            # Extract Airport ID\n",
    "            airport_id_element = soup.find('div', class_=\"row m-t-l m-l-l\")\n",
    "            airport_id_element = airport_id_element.find('h2')\n",
    "            airport_id = airport_id_element.text.strip()\n",
    "\n",
    "            # Add Airport ID to columns\n",
    "            for row in data:\n",
    "                if row[-1] == airport['Name']:  # Match airport name with row\n",
    "                    row.append(airport_id)  # Append airport_id to corresponding row\n",
    "        \n",
    "        driver.quit()\n",
    "        # Do not close the browser here, continue scraping other airports\n",
    "\n",
    "    # After scraping all airports, produce the data to Kafka\n",
    "    produce_to_kafka(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "airport_list = pd.read_csv(\"airport_list.csv\", header=None, names=[\"Name\", \"Link\"])\n",
    "\n",
    "# Specify the number of rows to scrape (if desired), or leave it as None to scrape all rows\n",
    "num_rows_to_scrape = 1  # Change this to the desired number of rows, or set it to None\n",
    "\n",
    "# Call the function with the airport_list and the specified number of rows\n",
    "airport_data = scrape_departures(airport_list, num_rows_to_scrape)\n",
    "\n",
    "# Get the date with year for the scraped data\n",
    "airport_data_with_date = get_date_with_year(airport_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError,KafkaException\n",
    "import json\n",
    "\n",
    "# Kafka Consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_consumer_group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "def consume_and_save_to_json(file_path):\n",
    "    c = Consumer(consumer_config)\n",
    "\n",
    "    # Subscribe to the 'Arrivals' topic\n",
    "    c.subscribe(['Arrivals'])\n",
    "\n",
    "    # List to hold received data\n",
    "    received_data = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = c.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition, consumer reached end of the topic\n",
    "                    break\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                try:\n",
    "                    # Deserialize JSON data\n",
    "                    data = json.loads(msg.value().decode('utf-8'))\n",
    "                    received_data.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    continue  # Skip to the next message\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer\n",
    "        c.close()\n",
    "\n",
    "        # Save received data to a JSON file\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(received_data, json_file, indent=4)\n",
    "\n",
    "# Specify the file path to save the JSON data\n",
    "json_file_path = 'Arrivals.json'\n",
    "\n",
    "# Call the function to consume data from Kafka and save it to JSON\n",
    "consume_and_save_to_json(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError,KafkaException\n",
    "import json\n",
    "\n",
    "# Kafka Consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_consumer_group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "def consume_and_save_to_json(file_path):\n",
    "    c = Consumer(consumer_config)\n",
    "\n",
    "    # Subscribe to the 'Arrivals' topic\n",
    "    c.subscribe(['Arrivals'])\n",
    "\n",
    "    # List to hold received data\n",
    "    received_data = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = c.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition, consumer reached end of the topic\n",
    "                    break\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                try:\n",
    "                    # Deserialize JSON data\n",
    "                    data = json.loads(msg.value().decode('utf-8'))\n",
    "                    received_data.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    continue  # Skip to the next message\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer\n",
    "        c.close()\n",
    "\n",
    "        # Save received data to a JSON file\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(received_data, json_file, indent=4)\n",
    "\n",
    "# Specify the file path to save the JSON data\n",
    "json_file_path = 'Arrivals.json'\n",
    "\n",
    "# Call the function to consume data from Kafka and save it to JSON\n",
    "consume_and_save_to_json(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_with_year(data):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    numeros_lignes = []\n",
    "    days = []\n",
    "    \n",
    "    # Convert data list to DataFrame\n",
    "    data_df = pd.DataFrame(data)\n",
    "    \n",
    "    for index, row in data_df.iterrows():\n",
    "        if row[0].split()[0] in [\"Monday,\", \"Tuesday,\", \"Wednesday,\", \"Thursday,\", \"Friday,\", \"Saturday,\", \"Sunday,\"]:\n",
    "            numeros_lignes.append(index)\n",
    "            days.append(row[0] + \" \" + str(current_year))  # Append current year\n",
    "    \n",
    "    # Add 'date' column to the DataFrame\n",
    "    data_df['date'] = ''\n",
    "    \n",
    "    for i in range(len(numeros_lignes) - 1):\n",
    "        data_df.iloc[numeros_lignes[i] + 1:numeros_lignes[i + 1] + 1, -1] = days[i]\n",
    "    \n",
    "    data_df.iloc[numeros_lignes[-1] + 1:-1, -1] = days[-1]\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
