{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# import csv\n",
    "# from bs4 import BeautifulSoup\n",
    "# from selenium.common import ElementNotInteractableException\n",
    "# from selenium.webdriver import Edge\n",
    "# from selenium.webdriver.common.by import By\n",
    "\n",
    "# # Replace YOUR-PATH-TO-CHROMEDRIVER with your chromedriver location\n",
    "# driver = Edge()\n",
    "\n",
    "# driver.get('https://flightradar24.com/data/airports/clt/arrivals')\n",
    "\n",
    "# time.sleep(3)\n",
    "\n",
    "# # Wait for the button to appear\n",
    "# button = driver.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "\n",
    "# # Click on the button\n",
    "# button.click()\n",
    "\n",
    "# time.sleep(3)\n",
    "\n",
    "# # Function to click on the \"Load earlier flights\" button and wait until it disappears\n",
    "# def click_load_earlier_until_disappear():\n",
    "#     while True:\n",
    "#         try:\n",
    "#             button = driver.find_element(By.XPATH,'//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load earlier flights\")]')\n",
    "#             button.click()\n",
    "#             time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "#         except ElementNotInteractableException:\n",
    "#             break\n",
    "\n",
    "# # Call the function to repeat the process\n",
    "# click_load_earlier_until_disappear()\n",
    "\n",
    "# # Get the HTML content of the page\n",
    "# html = driver.page_source\n",
    "\n",
    "# # Parse the HTML content\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# # Find the table element\n",
    "# table = soup.find('table', class_='table table-condensed table-hover data-table m-n-t-15')\n",
    "\n",
    "# # Extract data from the table\n",
    "# data = []\n",
    "# if table:\n",
    "#     rows = table.find_all('tr')\n",
    "#     for row in rows:\n",
    "#         cells = row.find_all('td')\n",
    "#         if cells:\n",
    "#             # Ensure consistent structure of each row\n",
    "#             row_data = [cell.text.strip() for cell in cells]\n",
    "#             # If row has fewer fields, add empty strings to match the expected number of fields\n",
    "#             if len(row_data) < 7:\n",
    "#                 row_data.extend([''] * (7 - len(row_data)))\n",
    "#             data.append(row_data)\n",
    "\n",
    "# # Split the data into halves\n",
    "# split_index = len(data) // 2\n",
    "# second_half_data = data[split_index-1:]\n",
    "\n",
    "# # Write the extracted data to a CSV file\n",
    "# csv_file = 'output.csv'\n",
    "# with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerows(second_half_data)\n",
    "\n",
    "# # Print a message indicating the CSV file has been created\n",
    "# print(\"CSV file created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# def get_date_with_year(data):\n",
    "#     current_year = datetime.now().year\n",
    "    \n",
    "#     numeros_lignes = []\n",
    "#     days = []\n",
    "    \n",
    "#     for index, row in data.iterrows():\n",
    "#         if row[0].split()[0] in [\"Monday,\", \"Tuesday,\", \"Wednesday,\", \"Thursday,\", \"Friday,\", \"Saturday,\", \"Sunday,\"]:\n",
    "#             numeros_lignes.append(index)\n",
    "#             days.append(row[0] + \" \" + str(current_year))  # Append current year\n",
    "    \n",
    "#     data['date'] = ''\n",
    "    \n",
    "#     for i in range(len(numeros_lignes) - 1):\n",
    "#         data.iloc[numeros_lignes[i] + 1:numeros_lignes[i + 1] + 1, -1] = days[i]\n",
    "    \n",
    "#     data.iloc[numeros_lignes[-1] + 1:-1, -1] = days[-1]\n",
    "    \n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# df= pd.read_csv(\"output.csv\" , header=None) \n",
    "# output_final  = get_date_with_year(df)\n",
    "# output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_final[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into halves\n",
    "# split_index = len(output_final) // 2\n",
    "# second_half_data = output_final[split_index-1:]\n",
    "# second_half_data.to_csv('output.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***chekpoint*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver import Edge\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Define the function to click the \"Load earlier flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_earlier_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load earlier flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "# Define the function to click the \"Load later flights\" button until it disappears or after a certain number of attempts\n",
    "def click_load_later_until_disappear(driver, max_attempts=5):\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"btn-flights-load\") and contains(text(), \"Load later flights\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(2)  # Adjust the sleep time according to your needs\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "def save_data_to_csv(data, airport_name, current_date):\n",
    "    # Remove invalid characters from the airport name\n",
    "    airport_name = re.sub(r'[\\\\/:\"*?<>|]+', '', airport_name)\n",
    "    \n",
    "    # Create folder path with date attached\n",
    "    folder_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}'  # Change this to the desired folder path\n",
    "    os.makedirs(folder_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    \n",
    "    # Create file path with airport name and date attached\n",
    "    file_path = os.path.join(folder_path, f\"Departures_{airport_name}_{current_date}.csv\")  # Add .csv extension\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def get_data_with_date(data,time_difference):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Initialize variables to store the last encountered date\n",
    "    last_date = ''\n",
    "    last_date_with_year = ''\n",
    "    \n",
    "    # Iterate through the data to append date with year as needed\n",
    "    for row in data:\n",
    "        if row[0].startswith(('Monday,', 'Tuesday,', 'Wednesday,', 'Thursday,', 'Friday,', 'Saturday,', 'Sunday,')):\n",
    "            last_date = row[0]\n",
    "            last_date_with_year = last_date + \" \" + str(current_year)\n",
    "        elif last_date_with_year:  # Append date with year if it exists\n",
    "            row.append(last_date_with_year)\n",
    "            row.append(time_difference)\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def scrape_departures(airport_list, num_rows=None):\n",
    "    # Determine the number of rows to iterate based on the provided parameter\n",
    "    if num_rows is not None:\n",
    "        airport_list = airport_list.head(num_rows)\n",
    "    \n",
    "    # Get current date\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Checkpoint file path\n",
    "    checkpoint_file_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}/DEPcheckpoint.csv'\n",
    "    \n",
    "    # Check if checkpoint file exists\n",
    "    if os.path.isfile(checkpoint_file_path):\n",
    "        checkpoint_df = pd.read_csv(checkpoint_file_path)\n",
    "        processed_airports = set(checkpoint_df['Name'])\n",
    "    else:\n",
    "        processed_airports = set()\n",
    "    \n",
    "    # options = webdriver.EdgeOptions()\n",
    "    # options.add_argument('--headless')\n",
    " \n",
    "   \n",
    "    # Loop through the specified number of rows in the airport list\n",
    "    for _, airport in airport_list.iterrows():\n",
    "        if airport['Name'] in processed_airports:\n",
    "            continue\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        # Append '/departures' to the link\n",
    "        departure_link = airport['Link'] + '/departures'\n",
    "        options = webdriver.EdgeOptions()\n",
    "        options.add_argument('--headless')\n",
    " \n",
    "        driver = webdriver.Edge()\n",
    "        driver.get(departure_link)\n",
    "        \n",
    "        time.sleep(4)\n",
    "\n",
    "        # Wait for the button to appear\n",
    "        try:\n",
    "            button = driver.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading earlier flights\n",
    "        click_load_earlier_until_disappear(driver)\n",
    "        \n",
    "        # Call the function to repeat the process 20 times for loading later flights\n",
    "        click_load_later_until_disappear(driver)\n",
    "\n",
    "        # Get the HTML content of the page after loading all flights\n",
    "        html = driver.page_source\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Initialize UTC and Local time strings\n",
    "        UTC = ''\n",
    "        Local = ''\n",
    "\n",
    "        # Regular expression pattern to match the time format HH:MM\n",
    "        time_pattern = re.compile(r'\\d{2}:\\d{2}')\n",
    "\n",
    "        # Loop until the Local time matches the time format\n",
    "        while not time_pattern.match(Local):\n",
    "            # Fetch UTC and Local time elements here\n",
    "            UTC_elements = soup.find('span', class_='text-base')\n",
    "            if UTC_elements:\n",
    "                UTC = UTC_elements.text.strip()\n",
    "\n",
    "            Local_elements = soup.find('span', class_='clock-time ng-binding')\n",
    "            if Local_elements:\n",
    "                Local = Local_elements.text.strip()\n",
    "            \n",
    "            time.sleep(2)\n",
    "                \n",
    "        local_time = datetime.strptime(Local,\"%H:%M\")\n",
    "        # Parse UTC time string into datetime object with a dummy date\n",
    "        utc_time = datetime.strptime(UTC,\"%H:%M\")\n",
    "        time_difference = utc_time - local_time\n",
    "\n",
    "        # Find the table element\n",
    "        table = soup.find('table', class_='table table-condensed table-hover data-table m-n-t-15')\n",
    "    \n",
    "        # Extract data from the table\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    # Ensure consistent structure of each row\n",
    "                    row_data = [cell.text.strip() for cell in cells]\n",
    "                    # If row has fewer fields, add empty strings to match the expected number of fields\n",
    "                    if len(row_data) < 7:\n",
    "                        row_data.extend([''] * (7 - len(row_data)))\n",
    "                    row_data.append(airport['Name'])  # Append airport name to each row\n",
    "                    data.append(row_data)\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "        # Process data to add date with date\n",
    "        data = get_data_with_date(data,time_difference)\n",
    "        \n",
    "        # Save data to CSV file for the current airport\n",
    "        save_data_to_csv(data, airport['Name'], current_date)\n",
    "        \n",
    "        # Update processed airports set\n",
    "        processed_airports.add(airport['Name'])\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_df = pd.DataFrame({'Name': list(processed_airports)})\n",
    "        checkpoint_df.to_csv(checkpoint_file_path, index=False)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "airport_list = pd.read_csv(\"airport_list.csv\", header=None, names=[\"Name\", \"Link\"])\n",
    "\n",
    "# Specify the number of rows to scrape (if desired), or leave it as None to scrape all rows\n",
    "num_rows_to_scrape = None # Change this to the desired number of rows, or set it to None\n",
    "\n",
    "# Call the function with the airport_list and the specified number of rows\n",
    "scrape_departures(airport_list, num_rows_to_scrape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n",
      "Message delivered to Departures [0]\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "\n",
    "# Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "\n",
    "def produce_to_kafka(data_df):\n",
    "    p = Producer(producer_config)\n",
    "\n",
    "    def delivery_report(err, msg):\n",
    "        \"\"\" Called once for each message produced to indicate delivery result.\n",
    "            Triggered by poll() or flush(). \"\"\"\n",
    "        if err is not None:\n",
    "            print('Message delivery failed: {}'.format(err))\n",
    "        else:\n",
    "            print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        # Convert row to JSON\n",
    "        json_data = row.to_json()\n",
    "\n",
    "        # Trigger any available delivery report callbacks from previous produce() calls\n",
    "        p.poll(0)\n",
    "\n",
    "        # Asynchronously produce a message.\n",
    "        p.produce('Departures', json_data.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "    # Wait for any outstanding messages to be delivered and delivery report callbacks to be triggered.\n",
    "    p.flush()\n",
    "\n",
    "# After getting airport_data_with_date from scraping\n",
    "produce_to_kafka(airport_data_with_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError,KafkaException\n",
    "import json\n",
    "\n",
    "# Kafka Consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_consumer_group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "def consume_and_save_to_json(file_path):\n",
    "    c = Consumer(consumer_config)\n",
    "\n",
    "    # Subscribe to the 'Arrivals' topic\n",
    "    c.subscribe(['Departures'])\n",
    "\n",
    "    # List to hold received data\n",
    "    received_data = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = c.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition, consumer reached end of the topic\n",
    "                    break\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                try:\n",
    "                    # Deserialize JSON data\n",
    "                    data = json.loads(msg.value().decode('utf-8'))\n",
    "                    received_data.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    continue  # Skip to the next message\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer\n",
    "        c.close()\n",
    "\n",
    "        # Save received data to a JSON file\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(received_data, json_file, indent=4)\n",
    "\n",
    "# Specify the file path to save the JSON data\n",
    "json_file_path = 'Departures.json'\n",
    "\n",
    "# Call the function to consume data from Kafka and save it to JSON\n",
    "consume_and_save_to_json(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
