{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import re\n",
    "\n",
    "def save_data_to_csv(data, airport_name, current_date):\n",
    "    # Remove invalid characters from the airport name\n",
    "    airport_name = re.sub(r'[\\\\/:\"*?<>|]+', '', airport_name)\n",
    "    \n",
    "    # Create folder path with date attached\n",
    "    folder_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}'  # Change this to the desired folder path\n",
    "    os.makedirs(folder_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    \n",
    "    # Create file path with airport name and date attached\n",
    "    file_path = os.path.join(folder_path, f\"Weather_{airport_name}_{current_date}.csv\")  # Add .csv extension\n",
    "    \n",
    "    # Extract fieldnames from data\n",
    "    fieldnames = set()\n",
    "    for row in data:\n",
    "        fieldnames.update(row.keys())\n",
    "    \n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "def save_checkpoint(processed_airports, current_date):\n",
    "    checkpoint_file_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}/checkpoint.csv'\n",
    "    checkpoint_df = pd.DataFrame({'Name': list(processed_airports)})\n",
    "    checkpoint_df.to_csv(checkpoint_file_path, index=False)\n",
    "\n",
    "def load_checkpoint(current_date):\n",
    "    checkpoint_file_path = f'c:/Users/httyd/Desktop/capstone/airports/Data/{current_date}/checkpoint.csv'\n",
    "    if os.path.isfile(checkpoint_file_path):\n",
    "        checkpoint_df = pd.read_csv(checkpoint_file_path)\n",
    "        processed_airports = set(checkpoint_df['Name'])\n",
    "    else:\n",
    "        processed_airports = set()\n",
    "    return processed_airports\n",
    "\n",
    "def scrape_weather(airport_list, num_rows=None):\n",
    "    # Get current date\n",
    "    current_date = time.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Load checkpoint\n",
    "    processed_airports = load_checkpoint(current_date)\n",
    "   \n",
    "    # Loop through the specified number of rows in the airport list\n",
    "    for _, airport in airport_list.iterrows():\n",
    "        if airport['Name'] in processed_airports:\n",
    "            continue\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        # Append '/weather' to the link\n",
    "        weather_link = airport['Link'] + '/weather'\n",
    "        \n",
    "        # Open the weather link in browser\n",
    "        options = webdriver.EdgeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Edge()\n",
    "        driver.get(weather_link)\n",
    "        \n",
    "        time.sleep(4)\n",
    "        \n",
    "        try:\n",
    "            button = driver.find_element(By.ID, 'onetrust-accept-btn-handler')\n",
    "            # Click on the button if it exists\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(3)\n",
    "        except NoSuchElementException:\n",
    "            pass  # If the button doesn't exist, move on\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Get the HTML content of the page\n",
    "        html = driver.page_source\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Find the table element\n",
    "        table = soup.find_all('tr', class_='slave')\n",
    "\n",
    "        # Extract data from the table\n",
    "        if table:\n",
    "            for row in table:\n",
    "                ul_elements = row.find_all('ul')\n",
    "                for ul in ul_elements:\n",
    "                    li_elements = ul.find_all('li')\n",
    "                    row_data = {}\n",
    "                    for li in li_elements:\n",
    "                        text = li.text.strip()\n",
    "                        key, value = text.split(':', 1)\n",
    "                        row_data[key.strip()] = value.strip()\n",
    "                    data.append(row_data)\n",
    "\n",
    "        # Extract Airport Name instead of ID\n",
    "        airport_name = airport['Name']\n",
    "\n",
    "        # Add Airport Name to columns\n",
    "        for row in data:\n",
    "            row['Airport_name'] = airport_name\n",
    "        \n",
    "                # Find all \"master expandable\" elements\n",
    "        \n",
    "        date_elements = soup.find_all('tr', class_='master expandable')\n",
    "\n",
    "        # Extract data from each \"master expandable\" element\n",
    "        for i, date_element in enumerate(date_elements):\n",
    "            # Extract the date from the second column (index 1)\n",
    "            date = date_element.find_all('td')[1].text.strip()\n",
    "\n",
    "            # Add the date to the corresponding row in the data list\n",
    "            if i < len(data):\n",
    "                data[i]['Date'] = date\n",
    "            else:\n",
    "                break  # If there are no more rows in the data list, exit the loop\n",
    "\n",
    "        \n",
    "        index_elements = soup.find_all('div', class_='chart-center')\n",
    "        if index_elements:\n",
    "            for index_element in index_elements:\n",
    "                index_element = index_element.find('span')\n",
    "                index = index_element.text.strip()\n",
    "\n",
    "                # Add the index value to each row in the data list\n",
    "                for row in data:\n",
    "                    row['index'] = index\n",
    "\n",
    "        # Save data to CSV file\n",
    "        save_data_to_csv(data, airport_name, current_date)\n",
    "        \n",
    "        # Update processed airports set\n",
    "        processed_airports.add(airport_name)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(processed_airports, current_date)\n",
    "        \n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "airport_list = pd.read_csv(\"airport_list.csv\", header=None, names=[\"Name\", \"Link\"])\n",
    "\n",
    "# Specify the number of rows to scrape (if desired), or leave it as None to scrape all rows\n",
    "num_rows_to_scrape = None # Change this to the desired number of rows, or set it to None\n",
    "\n",
    "# Call the function with the airport_list and the specified number of rows\n",
    "scrape_weather(airport_list, num_rows_to_scrape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
